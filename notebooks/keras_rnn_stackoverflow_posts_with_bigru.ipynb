{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification of StackOverflow using BiGRU RNNs with deep self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import pardir, getcwd\n",
    "from os.path import join, abspath\n",
    "PARENT_DIRECTORY = abspath(join(getcwd(), pardir))\n",
    "sys.path.insert(0, PARENT_DIRECTORY)\n",
    "\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "import talos as ta\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from definitions import  TALOS_DIR\n",
    "from app.preprocessing import (load_dataset, load_embeddings,\n",
    "                               preprocess_data, generate_embeddings_matrix)\n",
    "from app.models import load_biGRU_model, find_best_model_over_scan_logs\n",
    "from app.metrics import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for the loaded Dataset\n",
    "1. Format into *lowercase*\n",
    "2. Remove some of the *punctuation* characters\n",
    "3. Remove *Numbers*\n",
    "4. Remove *stopwords*\n",
    "5. Remove *links*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python    2000.0\n",
      "c         2000.0\n",
      "java      2000.0\n",
      "Name: tags, dtype: float64 ['python', 'c', 'java'] 3\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(tags_categories=['c', 'python', 'java'],load_from_pickle=True)\n",
    "classes_counts =data['tags'].value_counts().where(lambda cls: cls > 0).dropna() \n",
    "Classes = list(classes_counts.index)\n",
    "Nclasses = len(Classes)\n",
    "print(classes_counts, Classes, Nclasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Hyper parameter tuning for the  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% Train & 30% Test\n",
    "# 70% Train-Dev % 30* Train-Dev \n",
    "embeddings_voc, embeddings_vec = load_embeddings(load_from_pickle=True)\n",
    "model_data = preprocess_data(data, 'tags', 'post',\n",
    "                             input_ins='as_centroids',\n",
    "                             cv_split_dev=0.125)\n",
    "\n",
    "embeddings_matrix = generate_embeddings_matrix(embeddings_voc, embeddings_vec, model_data['words_index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  100,     2,   342,  2517,   599,    10,   452,  3686,   240,\n",
       "          87,   100,     2,   420,   593,   112,  5572,    67,   934,\n",
       "          16,    69,    10,   113,     3,     2,    32, 13392,     2,\n",
       "           3,    64,    16,     3,     2,   622,     2,     3,   386,\n",
       "           3,     2,   708,   240,    77,   189,   141,    32,   240,\n",
       "         268,    32,    77,   114,   268,     7,    32,    32,   126,\n",
       "         268,   240,   268,   463,   240,   268,    40,   240,   268,\n",
       "          16,   240,    77,   708,   240,   240,   141,   240,     5,\n",
       "         141,   708,   240,   240,    40,   708,   240,    16,   651,\n",
       "           2,     3,   162,     3,     2, 13393,     2,     3,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['x_train'][4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unistacked RNN with BiGRU & MLP on top of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TALOS_BiGRU_DEEP_LOG_FILENAME = 'talos_bigru_deep_log'\n",
    "talos_bigru_deep_log_pathname = os.path.join(TALOS_DIR, TALOS_BiGRU_DEEP_LOG_FILENAME)\n",
    "\n",
    "\n",
    "###### Production configuration\n",
    "rnn_deep_gru_config = {\n",
    "    \"model_type\": \"keras_deep_BiGRU_model\",\n",
    "    \"embedding_dim\": [embeddings_vec.shape[1]],\n",
    "    \"gru_size\": [200],\n",
    "    \"dense\": [300],\n",
    "    \"embeddings_matrix\": [embeddings_matrix],\n",
    "    \"visualize_process\": [True],\n",
    "    \"with_early_stoping\": [True],\n",
    "    \"multistack_run\": [False],\n",
    "    'early_stopping':[True],\n",
    "    'early_stopping_config__monitor': ['val_f1'],\n",
    "    'early_stopping_config__min_delta': [0],\n",
    "    'early_stopping_config__patience': [5],\n",
    "    'early_stopping_config__mode': ['max'],\n",
    "    \"embeddings_dropout\": [0.2],\n",
    "    \"var_dropout\": [0.2, 0.6],\n",
    "    \"mlp_dropout\": [0.2],\n",
    "    \"mlp_activation\": [\"softmax\"],\n",
    "    \"rnn_activation\": [\"sigmoid\", \"tanh\"],\n",
    "    \"optimizer\": [\"Nadam\", \"Adam\"],\n",
    "    \"batch_size\": [32, 64],\n",
    "    \"epochs\": [3]\n",
    "}\n",
    "\n",
    "history_model = ta.Scan(model_data['x_train'],\n",
    "                        model_data['y_train'],\n",
    "                        x_val=model_data['x_train_dev'],\n",
    "                        y_val=model_data['y_train_dev'],\n",
    "                        model=load_biGRU_model,\n",
    "                        params=rnn_deep_gru_config,\n",
    "                        grid_downsample=0.05,\n",
    "                        print_params=True,\n",
    "                        last_epoch_value=True,\n",
    "                        seed=(123),\n",
    "                        dataset_name=talos_bigru_deep_log_pathname\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Finds the best model configuration set for the BiGRU with deep self-attention, after the Talos Scanning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_talos = ta.Reporting(history_model)\n",
    "best_model_idx = report_talos.data['val_f1'].idxmax()\n",
    "best_model_params = report_talos.data.loc[best_model_idx].to_dict()\n",
    "best_model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train return am RNN BiGRU model with the the best configuration set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Load the best model of given the tuned featured model\n",
    "best_model_params['embeddings_matrix'] = embeddings_matrix\n",
    "best_model_params['early_stopping'] = True\n",
    "best_model_params['with_early_stopping'] = True\n",
    "best_model_params['visualize_process'] = True\n",
    "model_history, model = load_biGRU_model(model_data['x_train'],\n",
    "                                          model_data['y_train'],\n",
    "                                          model_data['x_train_dev'],\n",
    "                                          model_data['y_train_dev'],\n",
    "                                          best_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model History Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from app.visualization import plot_history_metrics\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plot_history_metrics(history_obj=model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance model\n",
    "\n",
    "Evaluates the performance of the best trained model in the **test** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(model_data_ftc['x_test'],\n",
    "                       model_data_ftc['y_test'],\n",
    "                       batch_size=best_model_params['batch_size'],\n",
    "                       verbose=1)\n",
    "\n",
    "print('\\nTest f1: %.4f' % (score[1]))\n",
    "print('\\nTest categorical accuracy: %.4f'% (score[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Prediction Perfomance  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from app.visualization import (plot_prediction_metrics,\n",
    "                               create_clf_report,\n",
    "                               plot_roc_curve,\n",
    "                               plot_precision_recall_curve,\n",
    "                               plot_confusion_matrix)\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "prediction_val = model.predict(model_data['x_test'], batch_size=best_model_params['batch_size'])\n",
    "\n",
    "# returns each entry result to the classification with the relevant probabilities\n",
    "y_pred_processed = np.array([np.argmax(val) for val in prediction_val])\n",
    "y_true_processed = np.array([np.argmax(val) for val in model_data['y_test']])\n",
    "\n",
    "# If you want to see the OneVSAll ROC Curves of each class uncomment the below line\n",
    "# plot_roc_curve(model_data['y_test'], prediction_val, Classes, 1)\n",
    "\n",
    "# If you want to see the OneVSAll Precission Recall Curves of each class, comment out the below line\n",
    "# plot_precision_recall_curve(model_data['y_test'], prediction_val, Classes , 1)\n",
    "\n",
    "# If you want to get the Classification Report, comment out the below line\n",
    "create_clf_report(model['y_test'], (prediction_val > 0.5).astype('int32'),\n",
    "                  y_true_processed, y_pred_processed)\n",
    "\n",
    "# If you want to get the confusion matrix,comment out the below line\n",
    "plot_confusion_matrix(y_true_processed, y_pred_processed, Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multistack RNN with BiGRU & MLP on top of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TALOS_BiGRU_DEEP_MUTLI_LOG_FILENAME = 'talos_bigru_deep_multi_log'\n",
    "talos_bigru_deep_multi_log_pathname = os.path.join(TALOS_DIR, TALOS_BiGRU_DEEP_MULTI_LOG_FILENAME)\n",
    "\n",
    "\n",
    "###### Production configuration\n",
    "rnn_deep_gru_multi_config = rnn_deep_gru_config.copy()\n",
    "rnn_deep_gru_multi_config.update({\n",
    "    \"model_type\": \"keras__BiGRU_multi_model\",\n",
    "    \"multistack_run\": [True],\n",
    "})\n",
    "\n",
    "history_model_multi = ta.Scan(model_data['x_train'],\n",
    "                        model_data['y_train'],\n",
    "                        x_val=model_data['x_train_dev'],\n",
    "                        y_val=model_data['y_train_dev'],\n",
    "                        model=load_biGRU_model,\n",
    "                        params=rnn_deep_gru_mult_config,\n",
    "                        grid_downsample=0.05,\n",
    "                        print_params=True,\n",
    "                        last_epoch_value=True,\n",
    "                        seed=(123),\n",
    "                        dataset_name=talos_bigru_deep_multi_log_pathname\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Finds the best model configuration set for the Multistacked BiGRU with deep self-attention, after the Talos Scanning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_talos_multi = ta.Reporting(history_model_multi)\n",
    "best_model_idx = report_talos_multi.data['val_f1'].idxmax()\n",
    "best_model_params_multi = report_talos_multi.data.loc[best_model_idx].to_dict()\n",
    "best_model_params_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train return an Multistacked RNN BiGRU model with the the best configuration set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Load the best model of given the tuned featured model\n",
    "best_model_params_multi['embeddings_matrix'] = embeddings_matrix\n",
    "model_history_multi, model_multi = load_lstm_model(model_data['x_train'],\n",
    "                                                   model_data['y_train'],\n",
    "                                                   model_data['x_train_dev'],\n",
    "                                                   model_data['y_train_dev'],\n",
    "                                                   best_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model History Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from app.visualization import plot_history_metrics\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plot_history_metrics(history_obj=model_history_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance model\n",
    "\n",
    "Evaluates the performance of the best trained model in the **test** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_multi = model_multi.evaluate(model_data['x_test'],\n",
    "                                   model_data['y_test'],\n",
    "                                   batch_size=best_model_params_multi['batch_size'],\n",
    "                                   verbose=1)\n",
    "\n",
    "print('\\nTest f1: %.4f' % (score_multi[1]))\n",
    "print('\\nTest categorical accuracy: %.4f'% (score_multi[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Prediction Perfomance  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from app.visualization import (plot_prediction_metrics,\n",
    "                               create_clf_report,\n",
    "                               plot_roc_curve,\n",
    "                               plot_precision_recall_curve,\n",
    "                               plot_confusion_matrix)\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "prediction_val_multi = model.predict(model_data['x_test'], batch_size=best_model_params['batch_size'])\n",
    "\n",
    "# returns each entry result to the classification with the relevant probabilities\n",
    "y_pred_processed_multi = np.array([np.argmax(val) for val in prediction_val_multi])\n",
    "y_true_processed_multi = np.array([np.argmax(val) for val in model_data['y_test']])\n",
    "\n",
    "# If you want to see the OneVSAll ROC Curves of each class uncomment the below line\n",
    "# plot_roc_curve(model_data['y_test'], prediction_val, Classes, 1)\n",
    "\n",
    "# If you want to see the OneVSAll Precission Recall Curves of each class, comment out the below line\n",
    "# plot_precision_recall_curve(model_data['y_test'], prediction_val, Classes , 1)\n",
    "\n",
    "# If you want to get the Classification Report, comment out the below line\n",
    "create_clf_report(model['y_test'], (prediction_val_multi > 0.5).astype('int32'),\n",
    "                  y_true_processed_multi, y_pred_processed_multi)\n",
    "\n",
    "# If you want to get the confusion matrix,comment out the below line\n",
    "plot_confusion_matrix(y_true_processed_multi, y_pred_processed_multi, Classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
