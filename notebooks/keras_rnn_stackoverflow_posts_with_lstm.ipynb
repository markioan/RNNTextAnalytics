{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification of StackOverflow using BiLSTM RNNs with deep self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import pardir, getcwd\n",
    "from os.path import join, abspath\n",
    "PARENT_DIRECTORY = abspath(join(getcwd(), pardir))\n",
    "sys.path.insert(0, PARENT_DIRECTORY)\n",
    "\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "import talos as ta\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from definitions import  TALOS_DIR\n",
    "from app.preprocessing import (load_dataset, load_embeddings,\n",
    "                               preprocess_data, save_embeddings_matrix)\n",
    "from app.models import load_bi_lstm_model, find_best_model_over_scan_logs\n",
    "from app.metrics import *\n",
    "\n",
    "#Comment out In case of Testing use only a set of the tags as dataset\n",
    "# tags_categories = ['c', 'python', 'java']\n",
    "# RUN_STATE = 'testing'\n",
    "\n",
    "#Comment out In case of Production use all the tags of the dataset\n",
    "tags_categories = \"__all__\"\n",
    "RUN_STATE = 'production'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for the loaded Dataset\n",
    "1. Format into *lowercase*\n",
    "2. Remove some of the *punctuation* characters\n",
    "3. Remove *Numbers*\n",
    "4. Remove *stopwords*\n",
    "5. Remove *links*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql              2000\n",
      "ruby-on-rails    2000\n",
      "android          2000\n",
      "angularjs        2000\n",
      "asp.net          2000\n",
      "c                2000\n",
      "c#               2000\n",
      "c++              2000\n",
      "css              2000\n",
      "html             2000\n",
      "ios              2000\n",
      "iphone           2000\n",
      "java             2000\n",
      "javascript       2000\n",
      "jquery           2000\n",
      "mysql            2000\n",
      "objective-c      2000\n",
      "php              2000\n",
      "python           2000\n",
      ".net             2000\n",
      "Name: tags, dtype: int64 ['sql', 'ruby-on-rails', 'android', 'angularjs', 'asp.net', 'c', 'c#', 'c++', 'css', 'html', 'ios', 'iphone', 'java', 'javascript', 'jquery', 'mysql', 'objective-c', 'php', 'python', '.net'] 20\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(tags_categories=tags_categories, load_from_pickle=True)\n",
    "classes_counts =data['tags'].value_counts().where(lambda cls: cls > 0).dropna() \n",
    "Classes = list(classes_counts.index)\n",
    "Nclasses = len(Classes)\n",
    "print(classes_counts, Classes, Nclasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Hyper parameter tuning for the  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% Train & 30% Test\n",
    "# 70% Train-Dev % 30* Train-Dev \n",
    "embeddings_voc, embeddings_vec = load_embeddings(load_from_pickle=True)\n",
    "model_data = preprocess_data(data, 'tags', 'post', cv_split_dev=0.125)\n",
    "embeddings_matrix_path = save_embeddings_matrix(embeddings_voc, embeddings_vec, model_data['words_index'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  54,   19, 2288,  766,  505,  211,  766, 1806,  766, 1923,   69,\n",
       "         81,  666,  149,   39,  202,  505,   94,   19,   54, 2288,  766,\n",
       "        505, 1335,  835, 2829,  766, 1560,  943,  513,  149,  310,  526,\n",
       "        156,  572, 2535,   65,   96, 1442,  101,  853,    2,   65,  101,\n",
       "         34,  144,  839,    2,   34,  224, 1166,  202,  505,   19,   54,\n",
       "       2288, 2829,  766,  943,  513,  149,  835,  526,  105,  278,  545,\n",
       "        572,   54,   19, 2288,  513,  766, 1923,  108,  835,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['x_train'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UniStacked RNN with BiLSTM & MLP on top of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Production configuration\n",
    "rnn_deep_lstm_config = {\n",
    "    \"model_type\": [\"keras_deep_LSTM_model\"],\n",
    "    \"embedding_dim\": [embeddings_vec.shape[1]],\n",
    "    \"lstm_size\": [200],\n",
    "    \"dense\": [300],\n",
    "    \"embeddings_matrix_path\": [embeddings_matrix_path],\n",
    "    \"visualize_process\": [True],\n",
    "    \"with_early_stoping\": [True],\n",
    "    \"multistack_run\": [False],\n",
    "    'early_stopping':[True],\n",
    "    'early_stopping_config__monitor': ['val_f1'],\n",
    "    'early_stopping_config__min_delta': [0],\n",
    "    'early_stopping_config__patience': [5],\n",
    "    'early_stopping_config__mode': ['max'],\n",
    "    \"embeddings_dropout\": [0.2],\n",
    "    \"var_dropout\": [0.2, 0.6],\n",
    "    \"mlp_dropout\": [0.2],\n",
    "    \"mlp_activation\": [\"softmax\"],\n",
    "    \"rnn_activation\": [\"relu\", \"tanh\"],\n",
    "    \"optimizer\": [\"Nadam\", \"Adam\"],\n",
    "    \"batch_size\": [32, 64],\n",
    "    \"epochs\": [3 if RUN_STATE == 'testing' else 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]WARNING: Logging before flag parsing goes to stderr.\n",
      "W0715 03:55:03.272535 140549419595584 deprecation_wrapper.py:119] From /home/giannhs/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0715 03:55:03.288831 140549419595584 deprecation_wrapper.py:119] From /home/giannhs/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0715 03:55:03.343727 140549419595584 deprecation_wrapper.py:119] From /home/giannhs/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0715 03:55:03.354533 140549419595584 deprecation_wrapper.py:119] From /home/giannhs/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0715 03:55:03.355253 140549419595584 deprecation_wrapper.py:119] From /home/giannhs/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_type': 'keras_deep_LSTM_model', 'embedding_dim': 300, 'lstm_size': 200, 'dense': 300, 'embeddings_matrix_path': 'embeddings-matrix-pickle', 'visualize_process': True, 'with_early_stoping': True, 'multistack_run': False, 'early_stopping': True, 'early_stopping_config__monitor': 'val_f1', 'early_stopping_config__min_delta': 0, 'early_stopping_config__patience': 5, 'early_stopping_config__mode': 'max', 'embeddings_dropout': 0.2, 'var_dropout': 0.2, 'mlp_dropout': 0.2, 'mlp_activation': 'softmax', 'rnn_activation': 'tanh', 'optimizer': 'Adam', 'batch_size': 64, 'epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0715 03:55:03.477378 140549419595584 deprecation.py:506] From /home/giannhs/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0715 03:55:03.803448 140549419595584 deprecation.py:323] From /home/giannhs/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0715 03:55:04.168659 140549419595584 deprecation_wrapper.py:119] From /home/giannhs/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 600, 300)          6000600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 600, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 600, 400)          801600    \n",
      "_________________________________________________________________\n",
      "deep_attention_1 (DeepAttent [(None, 400), (None, 600) 160801    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                6020      \n",
      "=================================================================\n",
      "Total params: 7,089,321\n",
      "Trainable params: 1,088,721\n",
      "Non-trainable params: 6,000,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92653af6072a4e59a8047cebe8509d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=10, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=24500, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.97056, saving model to keras_deep_LSTM_model\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.61567, saving model to keras_deep_LSTM_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=24500, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_accuracy improved from 0.97056 to 0.97809, saving model to keras_deep_LSTM_model\n",
      "\n",
      "Epoch 00002: val_f1 improved from 0.61567 to 0.74677, saving model to keras_deep_LSTM_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=24500, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_accuracy improved from 0.97809 to 0.98023, saving model to keras_deep_LSTM_model\n",
      "\n",
      "Epoch 00003: val_f1 improved from 0.74677 to 0.77692, saving model to keras_deep_LSTM_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=24500, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_accuracy improved from 0.98023 to 0.98103, saving model to keras_deep_LSTM_model\n",
      "\n",
      "Epoch 00004: val_f1 improved from 0.77692 to 0.78955, saving model to keras_deep_LSTM_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=24500, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_accuracy improved from 0.98103 to 0.98134, saving model to keras_deep_LSTM_model\n",
      "\n",
      "Epoch 00005: val_f1 improved from 0.78955 to 0.79535, saving model to keras_deep_LSTM_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=24500, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_accuracy improved from 0.98134 to 0.98221, saving model to keras_deep_LSTM_model\n",
      "\n",
      "Epoch 00006: val_f1 improved from 0.79535 to 0.80572, saving model to keras_deep_LSTM_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=24500, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.98221\n",
      "\n",
      "Epoch 00007: val_f1 did not improve from 0.80572\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=24500, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_accuracy improved from 0.98221 to 0.98254, saving model to keras_deep_LSTM_model\n",
      "\n",
      "Epoch 00008: val_f1 improved from 0.80572 to 0.81055, saving model to keras_deep_LSTM_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=24500, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.98254\n",
      "\n",
      "Epoch 00009: val_f1 improved from 0.81055 to 0.81231, saving model to keras_deep_LSTM_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=24500, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_accuracy improved from 0.98254 to 0.98261, saving model to keras_deep_LSTM_model\n",
      "\n",
      "Epoch 00010: val_f1 improved from 0.81231 to 0.81415, saving model to keras_deep_LSTM_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [3:39:52<00:00, 13192.96s/it]\n"
     ]
    }
   ],
   "source": [
    "TALOS_LSTM_DEEP_LOG_FILENAME = 'talos_lstm_deep_log'\n",
    "talos_lstm_deep_log_pathname = os.path.join(TALOS_DIR, TALOS_LSTM_DEEP_LOG_FILENAME)\n",
    "\n",
    "history_model = ta.Scan(model_data['x_train'],\n",
    "                        model_data['y_train'],\n",
    "                        x_val=model_data['x_train_dev'],\n",
    "                        y_val=model_data['y_train_dev'],\n",
    "                        model=load_bi_lstm_model,\n",
    "                        params=rnn_deep_lstm_config,\n",
    "                        grid_downsample=0.1,\n",
    "                        print_params=True,\n",
    "                        last_epoch_value=True,\n",
    "                        seed=(123),\n",
    "                        dataset_name=talos_lstm_deep_log_pathname\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Finds the best model configuration set for the LSTM with deep self-attention, after the Talos Scanning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'round_epochs': 10,\n",
       " 'val_loss': 0.6147428828307561,\n",
       " 'val_precision': 0.872153952053615,\n",
       " 'val_recall': 0.7642857144900731,\n",
       " 'val_f1': 0.8141458122389658,\n",
       " 'val_accuracy': 0.9826142841066633,\n",
       " 'val_categorical_accuracy': 0.8108571427209037,\n",
       " 'loss': 0.48062803679096455,\n",
       " 'precision': 0.893560794927636,\n",
       " 'recall': 0.7891836734401937,\n",
       " 'f1': 0.8376876486272228,\n",
       " 'accuracy': 0.984759175845555,\n",
       " 'categorical_accuracy': 0.8384897959086359,\n",
       " 'model_type': 'keras_deep_LSTM_model',\n",
       " 'embedding_dim': 300,\n",
       " 'lstm_size': 200,\n",
       " 'dense': 300,\n",
       " 'embeddings_matrix_path': 'embeddings-matrix-pickle',\n",
       " 'visualize_process': 'True',\n",
       " 'with_early_stoping': 'True',\n",
       " 'multistack_run': 'False',\n",
       " 'early_stopping': 'True',\n",
       " 'early_stopping_config__monitor': 'val_f1',\n",
       " 'early_stopping_config__min_delta': 0,\n",
       " 'early_stopping_config__patience': 5,\n",
       " 'early_stopping_config__mode': 'max',\n",
       " 'embeddings_dropout': 0.2,\n",
       " 'var_dropout': 0.2,\n",
       " 'mlp_dropout': 0.2,\n",
       " 'mlp_activation': 'softmax',\n",
       " 'rnn_activation': 'tanh',\n",
       " 'optimizer': 'Adam',\n",
       " 'batch_size': 64,\n",
       " 'epochs': 10}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_talos = ta.Reporting(history_model)\n",
    "best_model_idx = report_talos.data['val_f1'].idxmax()\n",
    "best_model_params = report_talos.data.loc[best_model_idx].to_dict()\n",
    "best_model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train return am RNN LSTM model with the the best configuration set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    # Train and Load the best model of given the tuned featured model\n",
    "    best_model_params['early_stopping'] = True\n",
    "    best_model_params['with_early_stopping'] = True\n",
    "    best_model_params['visualize_process'] = True\n",
    "    model_history, model = load_bi_lstm_model(model_data['x_train'],\n",
    "                                              model_data['y_train'],\n",
    "                                              model_data['x_train_dev'],\n",
    "                                              model_data['y_train_dev'],\n",
    "                                              best_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model History Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    from app.visualization import plot_history_metrics\n",
    "    import matplotlib.pylab as plt\n",
    "\n",
    "    %matplotlib inline\n",
    "    plot_history_metrics(history_obj=model_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance model\n",
    "\n",
    "Evaluates the performance of the best trained model in the **test** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    score = model.evaluate(model_data['x_test'],\n",
    "                           model_data['y_test'],\n",
    "                           batch_size=best_model_params['batch_size'],\n",
    "                           verbose=1)\n",
    "\n",
    "    print('\\nTest f1: %.4f' % (score[1]))\n",
    "    print('\\nTest categorical accuracy: %.4f'% (score[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Prediction Perfomance  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    import numpy as np\n",
    "    from app.visualization import (plot_prediction_metrics,\n",
    "                                   create_clf_report,\n",
    "                                   plot_roc_curve,\n",
    "                                   plot_precision_recall_curve,\n",
    "                                   plot_confusion_matrix)\n",
    "    import matplotlib.pylab as plt\n",
    "\n",
    "    prediction_val = model.predict(model_data['x_test'], batch_size=best_model_params['batch_size'])\n",
    "\n",
    "    # returns each entry result to the classification with the relevant probabilities\n",
    "    y_pred_processed = np.array([np.argmax(val) for val in prediction_val])\n",
    "    y_true_processed = np.array([np.argmax(val) for val in model_data['y_test']])\n",
    "\n",
    "    # If you want to see the OneVSAll ROC Curves of each class uncomment the below line\n",
    "    # plot_roc_curve(model_data['y_test'], prediction_val, Classes, 1)\n",
    "\n",
    "    # If you want to see the OneVSAll Precission Recall Curves of each class, comment out the below line\n",
    "    # plot_precision_recall_curve(model_data['y_test'], prediction_val, Classes , 1)\n",
    "\n",
    "    # If you want to get the Classification Report, comment out the below line\n",
    "    create_clf_report(model_data['y_test'], (prediction_val > 0.5).astype('int32'),\n",
    "                      y_true_processed, y_pred_processed)\n",
    "\n",
    "    # If you want to get the confusion matrix,comment out the below line\n",
    "    plot_confusion_matrix(y_true_processed, y_pred_processed, Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multistack RNN with BiLSTM & MLP on top of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_type': 'keras_deep_LSTM_multi_model', 'embedding_dim': 300, 'lstm_size': 200, 'dense': 300, 'embeddings_matrix_path': 'embeddings-matrix-pickle', 'visualize_process': True, 'with_early_stoping': True, 'multistack_run': True, 'early_stopping': True, 'early_stopping_config__monitor': 'val_f1', 'early_stopping_config__min_delta': 0, 'early_stopping_config__patience': 5, 'early_stopping_config__mode': 'max', 'embeddings_dropout': 0.2, 'var_dropout': 0.6, 'mlp_dropout': 0.2, 'mlp_activation': 'softmax', 'rnn_activation': 'tanh', 'optimizer': 'Nadam', 'batch_size': 64, 'epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0715 07:34:56.677434 140549419595584 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0715 07:34:56.693991 140549419595584 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0715 07:34:56.713730 140549419595584 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0715 07:34:56.731040 140549419595584 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0715 07:34:56.886838 140549419595584 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 600, 300)          6000600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 600, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 600, 400)          801600    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 600, 200)          480800    \n",
      "_________________________________________________________________\n",
      "deep_attention_1 (DeepAttent [(None, 200), (None, 600) 40401     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               60300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                6020      \n",
      "=================================================================\n",
      "Total params: 7,389,721\n",
      "Trainable params: 1,389,121\n",
      "Non-trainable params: 6,000,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66920a04af274dd395eefdb413e0f1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=10, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=24500, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.97254, saving model to keras_deep_LSTM_multi_model\n",
      "\n",
      "Epoch 00001: val_f1 improved from -inf to 0.67709, saving model to keras_deep_LSTM_multi_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600d1b2008de477da24b2002373599a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=24500, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e861b2148d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                         \u001b[0mlast_epoch_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                         \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtalos_lstm_deep_multi_log_pathname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                         )\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/talos/scan/Scan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, params, model, dataset_name, experiment_no, x_val, y_val, val_split, shuffle, round_limit, grid_downsample, random_method, seed, search_method, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, reduce_loss, last_epoch_value, clear_tf_session, disable_progress_bar, print_params, debug)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# input parameters section ends\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_null\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruntime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/talos/scan/Scan.py\u001b[0m in \u001b[0;36mruntime\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/talos/scan/scan_run.py\u001b[0m in \u001b[0;36mscan_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m                      disable=self.disable_progress_bar)\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_log\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/talos/scan/scan_round.py\u001b[0m in \u001b[0;36mscan_round\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0m_hr_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mingest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"unsupported operand type(s) for +: 'int' and 'numpy.str_'\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/talos/model/ingest_model.py\u001b[0m in \u001b[0;36mingest_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                       self.round_params)\n\u001b[0m",
      "\u001b[0;32m~/master_classes/text_analytics/RNNTextAnalytics/app/models.py\u001b[0m in \u001b[0;36mload_bi_lstm_model\u001b[0;34m(x_train, y_train, x_train_dev, y_train_dev, params)\u001b[0m\n\u001b[1;32m    218\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdefault_callbacks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                         shuffle=True)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/text_analytics/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TALOS_LSTM_DEEP_MULTI_LOG_FILENAME = 'talos_lstm_deep_multi_log'\n",
    "talos_lstm_deep_multi_log_pathname = os.path.join(TALOS_DIR, TALOS_LSTM_DEEP_MULTI_LOG_FILENAME)\n",
    "\n",
    "\n",
    "###### Production configuration\n",
    "rnn_deep_lstm_multi_config = rnn_deep_lstm_config.copy()\n",
    "rnn_deep_lstm_multi_config.update({\n",
    "    \"model_type\": [\"keras_deep_LSTM_multi_model\"],\n",
    "    \"multistack_run\": [True],\n",
    "})\n",
    "\n",
    "history_model_multi = ta.Scan(model_data['x_train'],\n",
    "                        model_data['y_train'],\n",
    "                        x_val=model_data['x_train_dev'],\n",
    "                        y_val=model_data['y_train_dev'],\n",
    "                        model=load_bi_lstm_model,\n",
    "                        params=rnn_deep_lstm_multi_config,\n",
    "                        grid_downsample=0.1,\n",
    "                        print_params=True,\n",
    "                        last_epoch_value=True,\n",
    "                        seed=(123),\n",
    "                        dataset_name=talos_lstm_deep_multi_log_pathname\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Finds the best model configuration set for the Multi LSTM with deep self-attention, after the Talos Scanning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_talos_multi = ta.Reporting(history_model_multi)\n",
    "best_model_idx = report_talos_multi.data['val_f1'].idxmax()\n",
    "best_model_params_multi = report_talos_multi.data.loc[best_model_idx].to_dict()\n",
    "best_model_params_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Train return a Multistack RNN LSTM model with the the best configuration set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    # Train and Load the best model of given the tuned featured model\n",
    "    model_history_multi, model_multi = load_bi_lstm_model(model_data['x_train'],\n",
    "                                                          model_data['y_train'],\n",
    "                                                          model_data['x_train_dev'],\n",
    "                                                          model_data['y_train_dev'],\n",
    "                                                          best_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize Model History Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    from app.visualization import plot_history_metrics\n",
    "    import matplotlib.pylab as plt\n",
    "\n",
    "    %matplotlib inline\n",
    "    plot_history_metrics(history_obj=model_history_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance model\n",
    "\n",
    "Evaluates the performance of the best trained model in the **test** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    score_multi = model_multi.evaluate(model_data['x_test'],\n",
    "                                       model_data['y_test'],\n",
    "                                       batch_size=best_model_params_multi['batch_size'],\n",
    "                                       verbose=1)\n",
    "\n",
    "    print('\\nTest f1: %.4f' % (score_multi[1]))\n",
    "    print('\\nTest categorical accuracy: %.4f'% (score_multi[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize Prediction Perfomance  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_STATE == 'testing':\n",
    "    import numpy as np\n",
    "    from app.visualization import (plot_prediction_metrics,\n",
    "                                   create_clf_report,\n",
    "                                   plot_roc_curve,\n",
    "                                   plot_precision_recall_curve,\n",
    "                                   plot_confusion_matrix)\n",
    "    import matplotlib.pylab as plt\n",
    "\n",
    "    prediction_val_multi = model.predict(model_data['x_test'], batch_size=best_model_params['batch_size'])\n",
    "\n",
    "    # returns each entry result to the classification with the relevant probabilities\n",
    "    y_pred_processed_multi = np.array([np.argmax(val) for val in prediction_val_multi])\n",
    "    y_true_processed_multi = np.array([np.argmax(val) for val in model_data['y_test']])\n",
    "\n",
    "    # If you want to see the OneVSAll ROC Curves of each class uncomment the below line\n",
    "    # plot_roc_curve(model_data['y_test'], prediction_val, Classes, 1)\n",
    "\n",
    "    # If you want to see the OneVSAll Precission Recall Curves of each class, comment out the below line\n",
    "    # plot_precision_recall_curve(model_data['y_test'], prediction_val, Classes , 1)\n",
    "\n",
    "    # If you want to get the Classification Report, comment out the below line\n",
    "    create_clf_report(model_data['y_test'], (prediction_val_multi > 0.5).astype('int32'),\n",
    "                      y_true_processed_multi, y_pred_processed_multi)\n",
    "\n",
    "    # If you want to get the confusion matrix,comment out the below line\n",
    "    plot_confusion_matrix(y_true_processed_multi, y_pred_processed_multi, Classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
