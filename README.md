# Assignment 3

## Participants
 - Karakolis Evangelos (P3351803)
 - Kontogeorgos Ioannis (P3351807)
 - Markopoulos Ioannis (P3351809)
 - Roumeliotis Anargyros (P3351817)

## Description
This project aims to create an MLP model that classifies the best stackoverflow's posts into the relevant programming languages. For the purpose of this project, we used an already formatted and structured dataset of *posts* and *tags* generated from Google's BigQuery.

The project has been split into three sections(notebooks).
    
   1. The *first* one transforms the *post* data into **TF-IDF Vectors** with and without Standardization. 
   
   2. The *second* one transforms the *post* data into **Centroids of word Embeddings** with and without Standardization. 
   
   3. The *third* finds the **best** tuned model parameter combination of the above 4 models and trains a MLP neural model with it.
   
   Each section contains a partition where it evaluates and visualizes the prediction performance of the best configured MLP model using the relevant metrics as *f1*, *accuracy*,  and visualizations as *Confusion Matrix* , *Classification Report*

## Project Structure

The project is structured with the below formation:
 
 1. Folder **/notebooks** which contains the jupyter notebooks implementation described above. 
 
 2. Folder **/app** which contains the code for the core functionality of the project and is structured as: 
    
       - *preprocessing.py* module, which contains all the functions that are used from the notebooks for the required data formation and processing.
       
       - *models.py* module, which contains the code for the MLPs models generation. The implementation is relevant to the *Talos* documentation in order to complete a successful parameter tuning for each model.
       
       - *metrics.py* module, which contains the code for the MLP models compilation metrics as *f1* , *accuracy*. etc
       
       - *visualization.py* module, which contains reusable code for the models performance visualization.
       
 3. Folder **data**, which contains all the reusable data sources or execution logs. It is worth to mention that the *talos* configuration lives under the subfolder *talos_logs*.
 
 4. Folder **models**, which has no actual value but is stores the autogenerated Keras models. 
 
 5. 'definitions.py' module, which contains some global variables and definitions which are essential for the project organization.
 
## Setup Instructions

   1. Create or load an existing conda environment
       ```
        conda env create -f requirements.yml
        conda activate text_analytics
       ```
        
        Useful reference [link](https://kapeli.com/cheat_sheets/Conda.docset/Contents/Resources/Documents/index)
   2. Install the packages from the *requiremets.txt* file
   3. Download the vocabulary that will be used in the project and place it under the */data* folder [Download here](https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz)
        
        #### Linux environments
        * `$>wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz`
        * `$>gzip -d cc.en.300.bin.gz`
   4. Download the **stackoverflow-posts** dataset and place i under the */data* folder. [Download dataset here](https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv)
 
## Runtime Instructions

   1. For the text classification models using **TF-IDF vectors** use the *keras_mlp_stackoverflow_posts_tf.ipyb* notebook. When the cell parameters tuning is ready for both models (with and without standardization) then 2 **Talos** log files will have been generated under the *data/talos_logs/* folder.
   
   2. For the text classification models using **Centroids of word Embeddings** use the *keras_mlp_stackoverflow_posts_ftc.ipyb* notebook. When the cell parameters tuning is ready for both models (with and without standardization) then 2 **Talos** log files will have been generated under the *data/talos_logs/* folder.
    
        **Caution**: Due to the great amount of memory usage of that implementation,
         it is suggested to clear all the other open kernels from other notebooks.
   
   3. After step 1 & 2 you get the best MLP Neural Network among all the registered combinations using the *keras_mlp_stackoverflow_posts_best_model.ipynb* notebook. It trains an MLP *Keras model* with the best loaded *Talos parameters* and visualizes it's performance at the test prediction. At the end of this notebook there is a comparison between the generated **MLP NN** model and a simple **Naive Bayes** model classifier in order to check whether the usage of an Neural Network was required for our classification problem.
   
   * *Important Note*: If you want to avoid the step 1 and 2 then you run step 3 individually as long as there are the relevant *talos_logs* into the */data* folder. 